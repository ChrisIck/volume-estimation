{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05bfff27-6484-4c9c-9f1a-b6aee6c612be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import stat\n",
    "\n",
    "BATCH_DIR = '/home/ci411/volume_estimation/batched_jobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f3d341-d628-4bc6-b8f6-6881940bce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import sys\n",
      "sys.path.append(\"/home/ci411/volume_estimation/\")\n",
      "\n",
      "import model_funcs\n",
      "import torch\n",
      "import os\n",
      "\n",
      "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "print('Using device:', device)\n",
      "print()\n",
      "\n",
      "MODELS_DIR = '/scratch/ci411/sonos_rirs/models/'\n",
      "FEATURES_DIR = '/scratch/ci411/sonos_rirs/features/'\n",
      "\n",
      "feature_set = 'cool_features'\n",
      "\n",
      "model_dict = {}\n",
      "model_dict['name'] = 'cool_model'\n",
      "model_dict['notes'] = 'testing the formatting'\n",
      "model_dict['data_path'] = os.path.join(FEATURES_DIR, feature_set, 'feature_df.csv')\n",
      "model_dict['model_path'] = os.path.join(MODELS_DIR, 'cool_experiment', model_dict['name'])\n",
      "\n",
      "model_funcs.train_model(model_funcs.Baseline_Model, model_dict, epochs=3000, batch_size=64, lr_init=0.0001, l2_reg=0.0001, overwrite=True, log=False, sched_thres=0.001, target='whatever')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_script = '''\n",
    "import sys\n",
    "sys.path.append(\"/home/ci411/volume_estimation/\")\n",
    "\n",
    "import model_funcs\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "MODELS_DIR = '/scratch/ci411/sonos_rirs/models/'\n",
    "FEATURES_DIR = '/scratch/ci411/sonos_rirs/features/'\n",
    "\n",
    "feature_set = '{feature_set}'\n",
    "\n",
    "model_dict = {{}}\n",
    "model_dict['name'] = '{model_name}'\n",
    "model_dict['notes'] = '{model_notes}'\n",
    "model_dict['data_path'] = os.path.join(FEATURES_DIR, feature_set, 'feature_df.csv')\n",
    "model_dict['model_path'] = os.path.join(MODELS_DIR, '{experiment_name}', model_dict['name'])\n",
    "\n",
    "model_funcs.train_model(model_funcs.Baseline_Model, model_dict, epochs={epochs}, batch_size={batch_size}, lr_init={lr_init}, l2_reg={l2_reg}, overwrite=True, log={log}, sched_thres={sched_thres}, target='{target}')\n",
    "'''\n",
    "\n",
    "#keys are feature_set, model_name, model_notes\n",
    "#batch_size, lr_init, l2_reg, log, sched_thres\n",
    "\n",
    "train_script_example = train_script.format(feature_set=\"cool_features\",model_name=\"cool_model\", model_notes=\"testing the formatting\",\\\n",
    "                                           experiment_name='cool_experiment',\\\n",
    "                                           epochs=3000, batch_size=64, lr_init=1e-4, l2_reg=1e-4, log=False, sched_thres=1e-3, target=\"whatever\")\n",
    "print(train_script_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f0fcf4d-4e2d-45fa-a25c-20ef49ae437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --job-name=jobbyjob\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --cpus-per-task=4\n",
      "#SBATCH --mem=32GB\n",
      "#SBATCH --time=47:59:59\n",
      "#SBATCH --mail-user=chris.ick@nyu.edu\n",
      "#SBATCH --export=NONE\n",
      "#SBATCH --output=\"o_jobbyjob-%j.out\"\n",
      "#SBATCH --gres=gpu:v100:1\n",
      "\n",
      "module purge\n",
      "module load anaconda3/2020.07\n",
      "\n",
      "source /home/ci411/.bashrc\n",
      "conda activate s3d_env\n",
      "python /home/ci411/volume_estimation/batched_jobs/science_time/jobbyjob.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_script = '''#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=32GB\n",
    "#SBATCH --time=47:59:59\n",
    "#SBATCH --mail-user=chris.ick@nyu.edu\n",
    "#SBATCH --export=NONE\n",
    "#SBATCH --output=\"o_{job_name}-%j.out\"\n",
    "#SBATCH --gres=gpu:{gre_spec}\n",
    "\n",
    "module purge\n",
    "module load anaconda3/2020.07\n",
    "\n",
    "source /home/ci411/.bashrc\n",
    "conda activate s3d_env\n",
    "python /home/ci411/volume_estimation/batched_jobs/{experiment_name}/{job_name}.py\n",
    "'''\n",
    "\n",
    "test_batch = batch_script.format(job_name=\"jobbyjob\", experiment_name=\"science_time\", gre_spec='v100:1')\n",
    "print(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33cfb2cb-ab10-4fda-b3db-41d73674446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['target'] = 'rt60'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081922_rt60_comp'\n",
    "run_template = 'prop{}_rt60_081922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081822_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target='rt60')\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7501f3d-bc12-4360-91f2-bf2f8aaa2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 2e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'rt60'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081922_rt60_comp'\n",
    "run_template = 'prop{}_rt60_081922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081822_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target='rt60')\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f99d81f-d39f-4ccb-9dcc-fdeda504215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'vol'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081822_comp'\n",
    "run_template = 'prop{}_20k_081822'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081822_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96487616-763e-4daf-9095-35685c1d486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'vol'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081822_2_comp'\n",
    "run_template = 'prop{}_20k_081522'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081522_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'ablation 1: lf phase + lf 1st deriv',\\\n",
    "              'ablation 2: mag + lf 1st deriv',\\\n",
    "              'ablation 3: mag + lf phase',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfcbe880-5967-43e9-9b47-7239534edbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 2e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'rt60'\n",
    "def_hyp['gre_spec'] = 'v100:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23f3247a-4f41-4fc3-b616-088b82907ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vary batch size on baseline model\n",
    "experiment_name = '082222_batch_size'\n",
    "run_template = 'bs_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "batch_sizes = [16,32,64,128,256,512,1028]\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "\n",
    "for i, bs in enumerate(batch_sizes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = \"varying batch size on baseline w/ batch_size {}\".format(bs)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=100, batch_size=bs,\\\n",
    "                                lr_init=def_hyp['lr_init'], l2_reg=def_hyp['l2_reg'],\\\n",
    "                                log=def_hyp['log'], sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d27df0a-f0dc-4f17-8ab6-5adbefbc1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary inital learning rate on baseline model\n",
    "experiment_name = '082222_learning_rate'\n",
    "run_template = 'lr_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "    \n",
    "#set variations\n",
    "learning_rates = np.logspace(-1, -8, 8)\n",
    "\n",
    "#adjust iteration\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    #rewrite notes\n",
    "    notes = \"varying initial learning rate w/ lr = {}\".format(lr)\n",
    "    #adjust parameter inputs\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=300, batch_size=def_hyp['batch_size'],\\\n",
    "                                lr_init=lr, l2_reg=def_hyp['l2_reg'],\\\n",
    "                                log=def_hyp['log'], sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    #clear down\n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aad5f4f0-8bc7-40f7-853b-234c8b21b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary l2 reg on baseline model\n",
    "experiment_name = '082222_l2_reg'\n",
    "run_template = 'l2_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "    \n",
    "#set variations\n",
    "reg_lambdas = np.logspace(-1, -5, 6)\n",
    "\n",
    "#adjust iteration\n",
    "for i, l2 in enumerate(reg_lambdas):\n",
    "    job_name = run_template.format(i)\n",
    "    #rewrite notes\n",
    "    notes = \"varying l2 reg parameter w/ lambda {}\".format(l2)\n",
    "    #adjust parameter inputs\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=500, batch_size=def_hyp['batch_size'],\\\n",
    "                                lr_init=def_hyp['lr_init'], l2_reg=l2,\\\n",
    "                                log=def_hyp['log'], sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    #clear down\n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c13f04a-5ed8-454f-87e7-aa735f062b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary scheduler threshold on baseline model\n",
    "experiment_name = '082222_sched_thres'\n",
    "run_template = 'st_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "    \n",
    "#set variations\n",
    "thresholds = np.logspace(-3,-8, 5)\n",
    "\n",
    "#adjust iteration\n",
    "for i, th in enumerate(thresholds):\n",
    "    job_name = run_template.format(i)\n",
    "    #rewrite notes\n",
    "    notes = \"varying scheduler thresholds with threshold {}\".format(th)\n",
    "    #adjust parameter inputs\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=500, batch_size=def_hyp['batch_size'],\\\n",
    "                                lr_init=def_hyp['lr_init'], l2_reg=def_hyp['l2_reg'],\\\n",
    "                                log=def_hyp['log'], sched_thres=th,\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    #clear down\n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b748703f-91a1-4f3f-98ca-95a5e283ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-03, 5.62341325e-05, 3.16227766e-06, 1.77827941e-07,\n",
       "       1.00000000e-08])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.logspace(-3,-8, 5)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ced3d-7f99-4766-a56a-b75de8449874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
