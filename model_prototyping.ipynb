{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa67b8d0-f013-4ba0-a615-12247bfc9ac7",
   "metadata": {},
   "source": [
    "# Model Prototyping\n",
    "\n",
    "Building the basis for our model experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753b036f-c5b8-44cc-a653-4712b3b19d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.nn import Conv2d, AvgPool2d, ReLU, Dropout, Flatten, Linear, Sequential, Module\n",
    "from torch.optim import Adam\n",
    "from time import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "MODELS_DIR  = '/scratch/ci411/sonos_rirs/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e62a78-bba4-453b-9961-dba6aa7ba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "model_dict['name'] = \"testrun2_regularization\"\n",
    "model_dict['notes'] = \"same as test run but with regularization\"\n",
    "model_dict['data_path'] = '/scratch/ci411/sonos_rirs/features/072622_small/feature_df.csv'\n",
    "model_dict['model_path'] = os.path.join(MODELS_DIR, model_dict['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13f9ea-8e81-447e-b228-3c1fa0b22de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Overwriting model at  /scratch/ci411/sonos_rirs/models/testrun2_regularization\n",
      "\n",
      "Loading data from  /scratch/ci411/sonos_rirs/features/072622_small/feature_df.csv\n",
      "Creating training dataloader\n",
      "Creating validation dataloader\n",
      "Creating test dataloader\n",
      "Feature batch shape: torch.Size([16, 1, 24, 1999])\n",
      "Labels batch shape: torch.Size([16])\n",
      "Beginning training for 25 epochs...\n",
      "Epoch: 0\tDuration: 33.25s\tTrain loss: 53624.2069\tVal loss: 42248.6459\tVal bias:-168.4519\tVal Pearson correlation: 1.3859e-01\tVal MeanMult: 6.4533\n",
      "Epoch: 1\tDuration: 33.17s\tTrain loss: 24428.1328\tVal loss: 13822.3769\tVal bias:-7.9113\tVal Pearson correlation: 1.9758e-01\tVal MeanMult: 2.0435\n",
      "Epoch: 2\tDuration: 33.48s\tTrain loss: 18431.6216\tVal loss: 13943.6408\tVal bias:14.8773\tVal Pearson correlation: 2.0030e-01\tVal MeanMult: 2.0779\n",
      "Epoch: 3\tDuration: 33.15s\tTrain loss: 18044.6136\tVal loss: 14047.0871\tVal bias:18.7579\tVal Pearson correlation: 2.0258e-01\tVal MeanMult: 2.0888\n",
      "Epoch: 4\tDuration: 32.97s\tTrain loss: 18065.8470\tVal loss: 13993.8417\tVal bias:17.8817\tVal Pearson correlation: 2.0387e-01\tVal MeanMult: 2.0836\n",
      "Epoch: 5\tDuration: 33.35s\tTrain loss: 18042.2295\tVal loss: 13892.9168\tVal bias:15.4700\tVal Pearson correlation: 2.0463e-01\tVal MeanMult: 2.0730\n",
      "Epoch: 6\tDuration: 33.18s\tTrain loss: 18010.0518\tVal loss: 13893.5382\tVal bias:16.2332\tVal Pearson correlation: 2.0666e-01\tVal MeanMult: 2.0732\n",
      "Epoch: 7\tDuration: 33.07s\tTrain loss: 17981.6053\tVal loss: 13784.4167\tVal bias:12.9987\tVal Pearson correlation: 2.0775e-01\tVal MeanMult: 2.0617\n",
      "Epoch: 8\tDuration: 33.46s\tTrain loss: 18019.7773\tVal loss: 13769.5163\tVal bias:13.0103\tVal Pearson correlation: 2.0798e-01\tVal MeanMult: 2.0603\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import model_funcs\n",
    "model_funcs.train_model(model_funcs.Baseline_Model, model_dict,\\\n",
    "                        overwrite=True, epochs=25,log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723b0f82-6ce6-489f-9c5a-10161015d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:15, 32.93it/s]\n"
     ]
    }
   ],
   "source": [
    "feat_df = pd.read_csv(model_dict['data_path'])\n",
    "model_path = os.path.join(MODELS_DIR, model_dict['name'])\n",
    "\n",
    "dataset = []\n",
    "\n",
    "    \n",
    "def create_dataloader(feature_df, batch_size=1, log=True):\n",
    "    dataset = []\n",
    "    for row in tqdm(feature_df.iterrows()):\n",
    "        feat_file = row[1]['file_feature']\n",
    "        loaded = np.load(feat_file)\n",
    "\n",
    "        feature = loaded['feat']\n",
    "        feature = feature.reshape((1, feature.shape[0], feature.shape[1]))\n",
    "        feature = np.real(feature)\n",
    "\n",
    "        vol = loaded['vol']\n",
    "        if log:\n",
    "            vol = np.log10(vol)\n",
    "        dataset.append((feature, vol))\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = create_dataloader(feat_df, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c987b41d-7f00-41cc-bb96-c6fdedc585f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name testrun2_regularization\n",
      "notes same as test run but with regularization\n",
      "data_path /scratch/ci411/sonos_rirs/features/072622_small/feature_df.csv\n",
      "model_path /scratch/ci411/sonos_rirs/models/testrun2_regularization\n"
     ]
    }
   ],
   "source": [
    "savename = './testmodeldict.json'\n",
    "with open(savename, 'w') as f:\n",
    "    json.dump(model_dict, f)\n",
    "    \n",
    "with open(savename) as f:\n",
    "    load_dict = json.load(f)\n",
    "    \n",
    "for key in load_dict.keys():\n",
    "    print(key, load_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a66ab9-e949-4408-943c-ade51b8c2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [00:00, 440.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:00, 466.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:00, 404.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = feat_df[feat_df['split']=='train']\n",
    "val_df = feat_df[feat_df['split']=='val']\n",
    "test_df = feat_df[feat_df['split']=='test']\n",
    "\n",
    "print(\"Creating training dataloader\")\n",
    "train_dataloader = create_dataloader(train_df, batch_size=16)\n",
    "\n",
    "print(\"Creating validation dataloader\")\n",
    "val_dataloader = create_dataloader(val_df)\n",
    "\n",
    "print(\"Creating test dataloader\")\n",
    "test_dataloader = create_dataloader(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f680db8-27a2-4db8-84d3-2ef287da00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([16, 1, 24, 1999])\n",
      "Labels batch shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c776c9f2-fba2-4f0f-9ea2-93f35ecaeb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Baseline_Model(Module):\n",
    "    def __init__(self, input_shape):\n",
    "        #accepts a tuple with the height/width of the feature\n",
    "        #matrix to set the FC layer dimensions\n",
    "        super(Baseline_Model, self).__init__()\n",
    "        \n",
    "        #block1\n",
    "        Conv1 = Conv2d(1, 30, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool1 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block2\n",
    "        Conv2 = Conv2d(30, 20, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool2 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block3\n",
    "        Conv3 = Conv2d(20, 10, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool3 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block4\n",
    "        Conv4 = Conv2d(10, 10, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool4 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block5\n",
    "        Conv5 = Conv2d(10, 5, kernel_size=(3,9), stride=(1,1))\n",
    "        Avgpool5 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block6\n",
    "        Conv6 = Conv2d(5, 5, kernel_size=(3,9), stride=(1,1))\n",
    "        Avgpool6 = AvgPool2d((2,2), stride=(2,2))\n",
    "\n",
    "        #dropout\n",
    "        dropout_layer = Dropout(p=0.5)\n",
    "        height5 = input_shape[0] - 2\n",
    "        height6 = (height5 - 2) // 2\n",
    "\n",
    "        time1 = (input_shape[1] - 9) // 2\n",
    "        time2 = (time1 - 9) // 2\n",
    "        time3 = (time2 - 9) // 2\n",
    "        time4 = (time3 - 9) // 2\n",
    "        time5 = (time4 - 7) // 2\n",
    "        time6 = (time5 - 7) // 2\n",
    "\n",
    "        flat_dims = 5 * height6 * time6\n",
    "        fc_layer = Linear(flat_dims, 1)\n",
    "        \n",
    "        self.net = Sequential(\n",
    "                    Conv1, ReLU(), Avgpool1,\n",
    "                    Conv2, ReLU(), Avgpool2,\n",
    "                    Conv3, ReLU(), Avgpool3,\n",
    "                    Conv4, ReLU(), Avgpool4,\n",
    "                    Conv5, ReLU(), Avgpool5,\n",
    "                    Conv6, ReLU(), Avgpool6,\n",
    "                    dropout_layer, Flatten(),\n",
    "                    fc_layer, Flatten()\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679cdf44-c94c-4f28-85ef-60136ca87ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = features.size()[2]\n",
    "input_width = features.size()[3]\n",
    "\n",
    "model = Baseline_Model((input_height, input_width)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c15e54c8-8449-4890-95ee-a5749982a306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 4.7331875006884045, 'bias': -2.123222233206245, 'pearson_cor': 0.1444998490590587, 'mean_mult': 132.80738737171563}\n"
     ]
    }
   ],
   "source": [
    "def MSE(output, target):\n",
    "    loss = torch.mean((output - target)**2)\n",
    "    return loss\n",
    "\n",
    "def Bias(output, target):\n",
    "    loss = torch.mean(output - target)\n",
    "    return loss\n",
    "\n",
    "def CovStep(output, target, output_mean, target_mean):\n",
    "    loss = torch.mean(((output - output_mean) * (target - target_mean)))\n",
    "    return loss\n",
    "\n",
    "def MeanAbsLogStep(output, target, log=True):\n",
    "    #convert out of log\n",
    "    if log:\n",
    "        vol_pred = 10**output\n",
    "        vol_target = 10**target\n",
    "    else:\n",
    "        vol_pred = output\n",
    "        vol_target = target\n",
    "    loss = torch.mean(torch.abs(torch.log(vol_pred/vol_target)))\n",
    "    return loss\n",
    "\n",
    "def compute_eval_metrics(dataloader, model, log=True):\n",
    "    target_sum = 0\n",
    "    pred_sum = 0\n",
    "    n_steps = 0\n",
    "    \n",
    "    for (x,y) in dataloader:        \n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        target_sum += y.sum()\n",
    "        pred_sum += pred.sum()\n",
    "        n_steps += 1\n",
    "    \n",
    "    target_mean = target_sum/n_steps\n",
    "    pred_mean = pred_sum/n_steps\n",
    "    \n",
    "    mse = 0\n",
    "    mean_error = 0\n",
    "    cov = 0\n",
    "    abs_log_ratio = 0\n",
    "    \n",
    "    var_pred = 0 #technically var * N but gets cancelled out in Pearson calculation\n",
    "    var_target = 0 \n",
    "    \n",
    "    for (x,y) in dataloader:        \n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        mse += MSE(pred, y)\n",
    "        mean_error += Bias(pred, y)\n",
    "        cov += CovStep(pred, y, pred_mean, target_mean)\n",
    "        abs_log_ratio += MeanAbsLogStep(pred, y, log=log)\n",
    "        \n",
    "        var_pred += MSE(pred, pred_mean)\n",
    "        var_target += MSE(y, target_mean)\n",
    "        \n",
    "        pears = CovStep(pred, y, pred_mean, target_mean)/(torch.sqrt(MSE(pred, pred_mean))*torch.sqrt(MSE(y, target_mean)))\n",
    "    \n",
    "    out_dict = {}\n",
    "    out_dict['mse'] = (mse / n_steps).item()\n",
    "    out_dict['bias'] = (mean_error / n_steps).item()\n",
    "    out_dict['pearson_cor'] = (cov/(torch.sqrt(var_pred) * torch.sqrt(var_target))).item()\n",
    "    out_dict['mean_mult'] = (torch.exp(abs_log_ratio/n_steps)).item()\n",
    "    \n",
    "    return out_dict\n",
    "    \n",
    "eval_dict = compute_eval_metrics(val_dataloader, model)\n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7ca9da7-3de4-4f84-a11e-2e7f123691ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tDuration: 24.69s\tTrain loss: 0.9086\tVal loss: 0.2417\tVal bias:0.1182\tVal Pearson correlation: 1.6877e-01\tVal MeanMult: 2.0553\n",
      "Epoch: 1\tDuration: 25.78s\tTrain loss: 0.2907\tVal loss: 0.2280\tVal bias:0.0105\tVal Pearson correlation: 3.6151e-01\tVal MeanMult: 2.1492\n",
      "Epoch: 2\tDuration: 26.24s\tTrain loss: 0.2826\tVal loss: 0.2304\tVal bias:0.0493\tVal Pearson correlation: 4.3434e-01\tVal MeanMult: 2.0868\n",
      "Epoch: 3\tDuration: 27.05s\tTrain loss: 0.2855\tVal loss: 0.2288\tVal bias:-0.0290\tVal Pearson correlation: 8.3376e-02\tVal MeanMult: 2.2419\n",
      "Epoch: 4\tDuration: 27.38s\tTrain loss: 0.2874\tVal loss: 0.2289\tVal bias:-0.0313\tVal Pearson correlation: 3.4533e-02\tVal MeanMult: 2.2483\n",
      "Epoch: 5\tDuration: 28.66s\tTrain loss: 0.2874\tVal loss: 0.2297\tVal bias:0.0423\tVal Pearson correlation: 4.0567e-02\tVal MeanMult: 2.0966\n",
      "Epoch: 6\tDuration: 28.58s\tTrain loss: 0.2887\tVal loss: 0.2280\tVal bias:0.0044\tVal Pearson correlation: 4.4734e-02\tVal MeanMult: 2.1609\n",
      "Epoch: 7\tDuration: 28.54s\tTrain loss: 0.2760\tVal loss: 0.2281\tVal bias:0.0129\tVal Pearson correlation: 4.4734e-02\tVal MeanMult: 2.1445\n",
      "Epoch: 8\tDuration: 28.49s\tTrain loss: 0.2853\tVal loss: 0.2290\tVal bias:-0.0330\tVal Pearson correlation: -5.5811e-16\tVal MeanMult: 2.2528\n",
      "Epoch: 9\tDuration: 28.44s\tTrain loss: 0.2766\tVal loss: 0.2289\tVal bias:0.0306\tVal Pearson correlation: -6.0664e-16\tVal MeanMult: 2.1139\n",
      "Epoch: 10\tDuration: 28.56s\tTrain loss: 0.2813\tVal loss: 0.2280\tVal bias:-0.0099\tVal Pearson correlation: -6.2012e-16\tVal MeanMult: 2.1918\n",
      "Epoch: 11\tDuration: 28.40s\tTrain loss: 0.2784\tVal loss: 0.2280\tVal bias:0.0095\tVal Pearson correlation: 6.0664e-16\tVal MeanMult: 2.1511\n",
      "Epoch: 12\tDuration: 28.35s\tTrain loss: 0.2673\tVal loss: 0.2296\tVal bias:0.0409\tVal Pearson correlation: 6.2012e-16\tVal MeanMult: 2.0986\n",
      "Epoch: 13\tDuration: 28.40s\tTrain loss: 0.2857\tVal loss: 0.2280\tVal bias:-0.0049\tVal Pearson correlation: -1.0483e-01\tVal MeanMult: 2.1806\n",
      "Epoch: 14\tDuration: 28.37s\tTrain loss: 0.2776\tVal loss: 0.2284\tVal bias:0.0226\tVal Pearson correlation: -8.9206e-02\tVal MeanMult: 2.1258\n",
      "Epoch: 15\tDuration: 28.33s\tTrain loss: 0.2777\tVal loss: 0.2283\tVal bias:0.0198\tVal Pearson correlation: -6.2012e-16\tVal MeanMult: 2.1312\n",
      "Epoch: 16\tDuration: 28.32s\tTrain loss: 0.2717\tVal loss: 0.2298\tVal bias:0.0435\tVal Pearson correlation: 6.0664e-16\tVal MeanMult: 2.0948\n",
      "Epoch: 17\tDuration: 28.33s\tTrain loss: 0.2748\tVal loss: 0.2302\tVal bias:0.0480\tVal Pearson correlation: 6.0664e-16\tVal MeanMult: 2.0883\n",
      "Epoch: 18\tDuration: 28.25s\tTrain loss: 0.2806\tVal loss: 0.2287\tVal bias:0.0275\tVal Pearson correlation: 6.0664e-16\tVal MeanMult: 2.1185\n",
      "Epoch: 19\tDuration: 28.25s\tTrain loss: 0.2723\tVal loss: 0.2303\tVal bias:0.0487\tVal Pearson correlation: -6.0664e-16\tVal MeanMult: 2.0875\n",
      "Epoch: 20\tDuration: 29.00s\tTrain loss: 0.2780\tVal loss: 0.2287\tVal bias:0.0275\tVal Pearson correlation: 5.5811e-16\tVal MeanMult: 2.1185\n",
      "Epoch: 21\tDuration: 28.69s\tTrain loss: 0.2681\tVal loss: 0.2290\tVal bias:0.0321\tVal Pearson correlation: nan\tVal MeanMult: 2.1117\n",
      "Epoch: 22\tDuration: 28.49s\tTrain loss: 0.2802\tVal loss: 0.2301\tVal bias:0.0462\tVal Pearson correlation: 6.0664e-16\tVal MeanMult: 2.0909\n",
      "Epoch: 23\tDuration: 28.38s\tTrain loss: 0.2804\tVal loss: 0.2356\tVal bias:0.0874\tVal Pearson correlation: 5.5702e-02\tVal MeanMult: 2.0603\n",
      "Epoch: 24\tDuration: 28.15s\tTrain loss: 0.2808\tVal loss: 0.2308\tVal bias:0.0537\tVal Pearson correlation: 3.7316e-02\tVal MeanMult: 2.0823\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(model.parameters(),lr=0.005, weight_decay=1e-2)\n",
    "\n",
    "hist = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"val_loss\": [],\n",
    "    \"val_bias\": [],\n",
    "    \"val_pearson_cor\": [],\n",
    "    \"val_mean_mult\": []\n",
    "}\n",
    "\n",
    "for ep in range(25):\n",
    "    t_start = time()\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    val_steps = 0\n",
    "    \n",
    "    for (x, y) in train_dataloader:\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        loss = MSE(pred, y.reshape((y.shape[0], 1)))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_loss += loss\n",
    "        train_steps += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_metrics = compute_eval_metrics(val_dataloader, model)\n",
    "    \n",
    "    \n",
    "    hist['train_loss'].append(train_loss/train_steps)\n",
    "    hist['val_loss'].append(val_metrics['mse'])\n",
    "    hist['val_bias'].append(val_metrics['bias'])\n",
    "    hist['val_pearson_cor'].append(val_metrics['pearson_cor'])\n",
    "    hist['val_mean_mult'].append(val_metrics['mean_mult'])\n",
    "    \n",
    "    t_end = time()\n",
    "    \n",
    "    t_elapsed = t_end - t_start\n",
    "    print(\"Epoch: {}\\tDuration: {:.2f}s\\tTrain loss: {:.4f}\\tVal loss: {:.4f}\\tVal bias:{:.4f}\\tVal Pearson correlation: {:.4e}\\tVal MeanMult: {:.4f}\"\\\n",
    "          .format(ep, t_elapsed, train_loss/train_steps, val_metrics['mse'],\\\n",
    "                  val_metrics['bias'], val_metrics['pearson_cor'],val_metrics['mean_mult']))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dbb35a4-183c-43d8-ab9a-00adaba3bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.04718757373347041, 'bias': 0.21722700967759592, 'pearson_cor': -4.86056656393074e-08, 'mean_mult': 1.6490241262038319}\n"
     ]
    }
   ],
   "source": [
    "eval_test = compute_eval_metrics(test_dataloader, model)\n",
    "print(eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3fd7026-863e-496b-bf18-0c22f39c92c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.keys()\n",
    "np.std(hist['val_loss'][15:])\n",
    "np.arange(100)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d55580-42a7-412a-9fbb-bcc65d189ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 423.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 3.5533725188865946, 'bias': -1.7790347908965678, 'pearson_cor': -0.16924566496616403, 'mean_mult': 60.12218988391525}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f67288-f36f-431b-8482-e6d4a76d29aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1847749759571498\n",
      "2.1847749743258196\n",
      "2.1847749763467244\n",
      "2.1847749806196854\n",
      "2.1847749823384\n",
      "2.184774982408507\n",
      "2.184774982342067\n",
      "2.1847749887373906\n",
      "2.1847749870368007\n",
      "2.1847749831466228\n",
      "2.1847749808330774\n",
      "2.1847749857464227\n",
      "2.1847749892471793\n",
      "2.184774983813266\n",
      "2.1847749695552214\n",
      "2.1847749768380846\n",
      "2.1847749785676336\n",
      "2.184774979268998\n",
      "2.1847749923730744\n",
      "2.1847749881828107\n"
     ]
    }
   ],
   "source": [
    "random_df = feat_df.sample(20)\n",
    "\n",
    "random_dataloader = create_dataloader(random_df)\n",
    "eval_random = compute_eval_metrics(random_dataloader, model)\n",
    "print(eval_random)\n",
    "\n",
    "for (x, y) in random_dataloader:\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        print(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8663c8c5-5077-4c39-99dd-e3ab55dba281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class print_Model(Module):\n",
    "    def __init__(self, seq):\n",
    "        super(print_Model, self).__init__()\n",
    "        self.net = seq\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Start\\n{}\".format(x.size()))\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "            print(layer)\n",
    "            print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52acb0b5-cf2a-4487-9527-7669b605568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9b10cc-e81a-4238-b988-3600a5b6554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 45796.25260507299\n",
      "bias 208.8553279556989\n",
      "pearson_cor 0.11266241132024864\n",
      "mean_mult 104.27601688167738\n",
      "310.9582128449743\n",
      "352.9361237221425\n",
      "66.39532032311823\n",
      "273.46949087948565\n",
      "203.54653305300818\n",
      "9.16723572200408\n",
      "-2.562087825488065\n",
      "22.972772472801477\n",
      "165.31293551814673\n",
      "150.62623389263476\n",
      "318.6727226084113\n",
      "98.86285874814143\n",
      "-29.583824657848435\n",
      "348.4388819273985\n",
      "236.10297180957184\n",
      "129.09428485168146\n",
      "139.32949064073074\n",
      "259.44537729097897\n",
      "149.21884106490478\n",
      "205.97660735221262\n"
     ]
    }
   ],
   "source": [
    "random_df = feat_df.sample(20)\n",
    "\n",
    "random_dataloader = create_dataloader(random_df, log=False)\n",
    "\n",
    "\n",
    "load_model = Baseline_Model((input_height, input_width)).to(device)\n",
    "model_name = 'testrun4_nonlog'\n",
    "load_model.load_state_dict(torch.load(os.path.join(MODELS_DIR,model_name,'model_state.pt'), map_location=torch.device('cpu')))\n",
    "\n",
    "load_metrics = compute_eval_metrics(test_dataloader, load_model, log=False)\n",
    "for key in load_metrics.keys():\n",
    "    print(key, load_metrics[key])\n",
    "\n",
    "for (x, y) in random_dataloader:\n",
    "    (x, y) = (x.to(device), y.to(device))\n",
    "    pred = load_model(x)\n",
    "    print(pred.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "469273db-2880-4c15-a8c5-834d1a0e9737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_df['vol'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f849c6-7e63-4eba-9105-9ec1c4a214b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3d_kernel",
   "language": "python",
   "name": "s3d_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
